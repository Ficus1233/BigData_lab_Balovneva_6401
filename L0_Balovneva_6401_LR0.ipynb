{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82OvPKEiEqjc"
      },
      "source": [
        "# Введение в MapReduce модель на Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JQ2cvXLjICmI"
      },
      "outputs": [],
      "source": [
        "from typing import NamedTuple # requires python 3.6+\n",
        "from typing import Iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yjPHumVwEyEg"
      },
      "outputs": [],
      "source": [
        "def MAP(_, row:NamedTuple):\n",
        "    if (row.gender == 'female'):\n",
        "        yield (row.age, row)\n",
        "        \n",
        "def REDUCE(age:str, rows:Iterator[NamedTuple]):\n",
        "    sum = 0\n",
        "    count = 0\n",
        "    for row in rows:\n",
        "        sum += row.social_contacts\n",
        "        count += 1\n",
        "    if (count > 0):\n",
        "        yield (age, sum/count)\n",
        "    else:\n",
        "        yield (age, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBKMgpG_ilaZ"
      },
      "source": [
        "Модель элемента данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Rv-XIjhTJPx3"
      },
      "outputs": [],
      "source": [
        "class User(NamedTuple):\n",
        "    id: int\n",
        "    age: str\n",
        "    social_contacts: int\n",
        "    gender: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5KV0Ze2vQgu5"
      },
      "outputs": [],
      "source": [
        "input_collection = [\n",
        "    User(id=0, age=55, gender='male', social_contacts=20),\n",
        "    User(id=1, age=25, gender='female', social_contacts=240),\n",
        "    User(id=2, age=25, gender='female', social_contacts=500),\n",
        "    User(id=3, age=33, gender='female', social_contacts=800)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFeqzyZxZIFZ"
      },
      "source": [
        "Функция RECORDREADER моделирует чтение элементов с диска или по сети."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S5HR4E_GQoMJ"
      },
      "outputs": [],
      "source": [
        "def RECORDREADER():\n",
        "    return [(u.id, u) for u in input_collection]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "NeEoWla-ROUy",
        "outputId": "94ca6e0e-4644-4282-acbf-1759d7ba2918"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, User(id=0, age=55, social_contacts=20, gender='male')),\n",
              " (1, User(id=1, age=25, social_contacts=240, gender='female')),\n",
              " (2, User(id=2, age=25, social_contacts=500, gender='female')),\n",
              " (3, User(id=3, age=33, social_contacts=800, gender='female'))]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(RECORDREADER())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YB8orgPSZs8M"
      },
      "outputs": [],
      "source": [
        "def flatten(nested_iterable):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "74oyvDLaRmd5",
        "outputId": "c6147702-7153-47c7-a574-d5fe6abe29a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(25, User(id=1, age=25, social_contacts=240, gender='female')),\n",
              " (25, User(id=2, age=25, social_contacts=500, gender='female')),\n",
              " (33, User(id=3, age=33, social_contacts=800, gender='female'))]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "map_output = flatten(map(lambda x: MAP(*x), RECORDREADER()))\n",
        "map_output = list(map_output) # materialize\n",
        "map_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8ncYDJ3-VzDn"
      },
      "outputs": [],
      "source": [
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return t.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "cKzY_6COWOA2",
        "outputId": "e6791b12-e409-47e9-bcd4-e9f8ca8611bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(25,\n",
              "  [User(id=1, age=25, social_contacts=240, gender='female'),\n",
              "   User(id=2, age=25, social_contacts=500, gender='female')]),\n",
              " (33, [User(id=3, age=33, social_contacts=800, gender='female')])]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shuffle_output = groupbykey(map_output)\n",
        "shuffle_output = list(shuffle_output)\n",
        "shuffle_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NlA7lkDDYL0t",
        "outputId": "6b25d03f-5c92-4f3b-f500-6d70acd598b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(25, 370.0), (33, 800.0)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reduce_output = flatten(map(lambda x: REDUCE(*x), shuffle_output))\n",
        "reduce_output = list(reduce_output)\n",
        "reduce_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf6qhHEtd6bI"
      },
      "source": [
        "Все действия одним конвейером!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dZaQGYxCdpw5",
        "outputId": "3f5c6425-e5c5-49d2-b2cd-ce58a9acc33c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(25, 370.0), (33, 800.0)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER()))))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq3EWRIpwSiJ"
      },
      "source": [
        "# **MapReduce**\n",
        "Выделим общую для всех пользователей часть системы в отдельную функцию высшего порядка. Это наиболее простая модель MapReduce, без учёта распределённого хранения данных. \n",
        "\n",
        "Пользователь для решения своей задачи реализует RECORDREADER, MAP, REDUCE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V1PZeQMwwVjc"
      },
      "outputs": [],
      "source": [
        "def flatten(nested_iterable):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return t.items()\n",
        "\n",
        "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
        "    return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFIVrimep678"
      },
      "source": [
        "## Спецификация MapReduce\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "f (k1, v1) -> (k2,v2)*\n",
        "g (k2, v2*) -> (k3,v3)*\n",
        " \n",
        "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
        "groupby ((k2,v2)*) -> (k2,v2*)*\n",
        "flatten (e2**) -> e2*\n",
        " \n",
        "mapreduce .map(f).flatten.groupby(k2).map(g).flatten\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtTFyqke3KGe"
      },
      "source": [
        "# Примеры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNhh5763w5Vn"
      },
      "source": [
        "## SQL "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QkyurnvGxBGk",
        "outputId": "84761282-d2ba-435a-e8d7-a85150730e10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(25, 370.0), (33, 800.0)]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import NamedTuple # requires python 3.6+\n",
        "from typing import Iterator\n",
        "\n",
        "class User(NamedTuple):\n",
        "    id: int\n",
        "    age: str\n",
        "    social_contacts: int\n",
        "    gender: str\n",
        "        \n",
        "input_collection = [\n",
        "        User(id=0, age=55, gender='male', social_contacts=20),\n",
        "        User(id=1, age=25, gender='female', social_contacts=240),\n",
        "        User(id=2, age=25, gender='female', social_contacts=500),\n",
        "        User(id=3, age=33, gender='female', social_contacts=800)\n",
        "]\n",
        "\n",
        "def MAP(_, row:NamedTuple):\n",
        "    if (row.gender == 'female'):\n",
        "        yield (row.age, row)\n",
        "        \n",
        "def REDUCE(age:str, rows:Iterator[NamedTuple]):\n",
        "    sum = 0\n",
        "    count = 0\n",
        "    for row in rows:\n",
        "        sum += row.social_contacts\n",
        "        count += 1\n",
        "    if (count > 0):\n",
        "        yield (age, sum/count)\n",
        "    else:\n",
        "        yield (age, 0)\n",
        " \n",
        "def RECORDREADER():\n",
        "    return [(u.id, u) for u in input_collection]\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNKYIeerx0nY"
      },
      "source": [
        "## Matrix-Vector multiplication "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "rwcntRcCyi1V",
        "outputId": "606737ab-6b55-455c-931f-4fc45155f8a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, np.float64(2.0379767510476)),\n",
              " (1, np.float64(2.0379767510476)),\n",
              " (2, np.float64(2.0379767510476)),\n",
              " (3, np.float64(2.0379767510476)),\n",
              " (4, np.float64(2.0379767510476))]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Iterator\n",
        "import numpy as np\n",
        "\n",
        "mat = np.ones((5,4))\n",
        "vec = np.random.rand(4) # in-memory vector in all map tasks\n",
        "\n",
        "def MAP(coordinates:(int, int), value:int):\n",
        "    i, j = coordinates\n",
        "    yield (i, value*vec[j])\n",
        " \n",
        "def REDUCE(i:int, products:Iterator[NamedTuple]):\n",
        "    sum = 0\n",
        "    for p in products:\n",
        "        sum += p\n",
        "    yield (i, sum)\n",
        "\n",
        "def RECORDREADER():\n",
        "    for i in range(mat.shape[0]):\n",
        "        for j in range(mat.shape[1]):\n",
        "            yield ((i, j), mat[i,j])\n",
        "            \n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruZREYdi2o4O"
      },
      "source": [
        "## Inverted index "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "vt9H9Alf3TYv",
        "outputId": "51aeffc9-e111-4607-bd84-cfcc7b56f238"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('what', ['0', '1']),\n",
              " ('is', ['0', '1', '2']),\n",
              " ('it', ['0', '1', '2']),\n",
              " ('banana', ['2']),\n",
              " ('a', ['2'])]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Iterator\n",
        "\n",
        "d1 = \"it is what it is\"\n",
        "d2 = \"what is it\"\n",
        "d3 = \"it is a banana\"\n",
        "documents = [d1, d2, d3]\n",
        "\n",
        "def RECORDREADER():\n",
        "    for (docid, document) in enumerate(documents):\n",
        "        yield (\"{}\".format(docid), document)\n",
        "            \n",
        "def MAP(docId:str, body:str):\n",
        "    for word in set(body.split(' ')):\n",
        "        yield (word, docId)\n",
        " \n",
        "def REDUCE(word:str, docIds:Iterator[str]):\n",
        "    yield (word, sorted(docIds))\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7az-6DA6qr2"
      },
      "source": [
        "## WordCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dN-nbtgG6uYG",
        "outputId": "24117576-7931-401d-a581-28e246b23453"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('', 3), ('it', 9), ('is', 9), ('what', 5), ('a', 1), ('banana', 1)]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Iterator\n",
        "\n",
        "d1 = \"\"\"\n",
        "it is what it is\n",
        "it is what it is\n",
        "it is what it is\"\"\"\n",
        "d2 = \"\"\"\n",
        "what is it\n",
        "what is it\"\"\"\n",
        "d3 = \"\"\"\n",
        "it is a banana\"\"\"\n",
        "documents = [d1, d2, d3]\n",
        "\n",
        "def RECORDREADER():\n",
        "    for (docid, document) in enumerate(documents):\n",
        "        for (lineid, line) in enumerate(document.split('\\n')):\n",
        "            yield (\"{}:{}\".format(docid,lineid), line)\n",
        "\n",
        "def MAP(docId:str, line:str):\n",
        "    for word in line.split(\" \"):  \n",
        "        yield (word, 1)\n",
        " \n",
        "def REDUCE(word:str, counts:Iterator[int]):\n",
        "    sum = 0\n",
        "    for c in counts:\n",
        "        sum += c\n",
        "    yield (word, sum)\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-jRAcYCAkkk"
      },
      "source": [
        "# MapReduce Distributed\n",
        "\n",
        "Добавляется в модель фабрика RECORDREARER-ов --- INPUTFORMAT, функция распределения промежуточных результатов по партициям PARTITIONER, и функция COMBINER для частичной аггрегации промежуточных результатов до распределения по новым партициям."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nw-b-xJsApgW"
      },
      "outputs": [],
      "source": [
        "def flatten(nested_iterable):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return t.items()\n",
        "            \n",
        "            \n",
        "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
        "    global reducers\n",
        "    partitions = [dict() for _ in range(reducers)]\n",
        "    for map_partition in map_partitions:\n",
        "        for (k2, v2) in map_partition:\n",
        "            p = partitions[PARTITIONER(k2)]\n",
        "            p[k2] = p.get(k2, []) + [v2]\n",
        "    return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in enumerate(partitions)]\n",
        " \n",
        "def PARTITIONER(obj):\n",
        "    global reducers\n",
        "    return hash(obj) % reducers\n",
        "    \n",
        "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
        "    map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
        "    if COMBINER != None:\n",
        "        map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
        "    reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER) # shuffle\n",
        "    reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
        "    \n",
        "    print(\"{} key-value pairs were sent over a network.\".format(sum([len(vs) for (k,vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
        "    return reduce_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxirlf3XqZxY"
      },
      "source": [
        "## Спецификация MapReduce Distributed\n",
        "\n",
        "\n",
        "```\n",
        "f (k1, v1) -> (k2,v2)*\n",
        "g (k2, v2*) -> (k3,v3)*\n",
        " \n",
        "e1 (k1, v1)\n",
        "e2 (k2, v2)\n",
        "partition1 (k2, v2)*\n",
        "partition2 (k2, v2*)*\n",
        " \n",
        "flatmap (e1->e2*, e1*) -> partition1*\n",
        "groupby (partition1*) -> partition2*\n",
        "\n",
        "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
        "mapreduce .flatmap(f).groupby(k2).flatmap(g)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWYw_CpbbY3C"
      },
      "source": [
        "## WordCount "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "uR_zfGFkMZlp",
        "outputId": "c8d46167-473d-43b9-881a-2396991b3731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "56 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0, [('', 6), ('is', 18), ('it', 18), ('what', 10)]),\n",
              " (1, [('a', 2), ('banana', 2)])]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Iterator\n",
        "import numpy as np\n",
        "\n",
        "d1 = \"\"\"\n",
        "it is what it is\n",
        "it is what it is\n",
        "it is what it is\"\"\"\n",
        "d2 = \"\"\"\n",
        "what is it\n",
        "what is it\"\"\"\n",
        "d3 = \"\"\"\n",
        "it is a banana\"\"\"\n",
        "documents = [d1, d2, d3, d1, d2, d3]\n",
        "\n",
        "maps = 3\n",
        "reducers = 2\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    global maps\n",
        "    \n",
        "    def RECORDREADER(split):\n",
        "        for (docid, document) in enumerate(split):\n",
        "            for (lineid, line) in enumerate(document.split('\\n')):\n",
        "                yield (\"{}:{}\".format(docid,lineid), line)\n",
        "            \n",
        "    split_size =  int(np.ceil(len(documents)/maps))\n",
        "    for i in range(0, len(documents), split_size):\n",
        "        yield RECORDREADER(documents[i:i+split_size])\n",
        "\n",
        "def MAP(docId:str, line:str):\n",
        "    for word in line.split(\" \"):  \n",
        "        yield (word, 1)\n",
        " \n",
        "def REDUCE(word:str, counts:Iterator[int]):\n",
        "    sum = 0\n",
        "    for c in counts:\n",
        "        sum += c\n",
        "    yield (word, sum)\n",
        "    \n",
        "# try to set COMBINER=REDUCER and look at the number of values sent over the network \n",
        "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None) \n",
        "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
        "partitioned_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCJGx8IQ87xS"
      },
      "source": [
        "## TeraSort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "P2v8v1v_8_YR",
        "outputId": "e0987c25-9757-46cb-8e55-d5d2adfbee2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  [(None, np.float64(0.03723819546990548)),\n",
              "   (None, np.float64(0.044318385932148874)),\n",
              "   (None, np.float64(0.08036325344029338)),\n",
              "   (None, np.float64(0.09211984893489888)),\n",
              "   (None, np.float64(0.11905744791336048)),\n",
              "   (None, np.float64(0.14172151248973663)),\n",
              "   (None, np.float64(0.1673077710265667)),\n",
              "   (None, np.float64(0.16921896112039547)),\n",
              "   (None, np.float64(0.19639196696191297)),\n",
              "   (None, np.float64(0.22954645968125753)),\n",
              "   (None, np.float64(0.23279492209897945)),\n",
              "   (None, np.float64(0.24264545455275277)),\n",
              "   (None, np.float64(0.24870622053052716)),\n",
              "   (None, np.float64(0.2982273298821676)),\n",
              "   (None, np.float64(0.36162263499698666)),\n",
              "   (None, np.float64(0.39961347346689857)),\n",
              "   (None, np.float64(0.412075652389465)),\n",
              "   (None, np.float64(0.4754386973596959)),\n",
              "   (None, np.float64(0.47688639965809454))]),\n",
              " (1,\n",
              "  [(None, np.float64(0.5348847876245267)),\n",
              "   (None, np.float64(0.5834772189529805)),\n",
              "   (None, np.float64(0.6860580068813238)),\n",
              "   (None, np.float64(0.6986046726765601)),\n",
              "   (None, np.float64(0.7399965321261299)),\n",
              "   (None, np.float64(0.7689187521808161)),\n",
              "   (None, np.float64(0.7825692727005485)),\n",
              "   (None, np.float64(0.8868126127134336)),\n",
              "   (None, np.float64(0.9164959080339944)),\n",
              "   (None, np.float64(0.9425799230330566)),\n",
              "   (None, np.float64(0.9856461146442326))])]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "input_values = np.random.rand(30)\n",
        "maps = 3\n",
        "reducers = 2\n",
        "min_value = 0.0\n",
        "max_value = 1.0\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    global maps\n",
        "    \n",
        "    def RECORDREADER(split):\n",
        "        for value in split:\n",
        "                yield (value, None)\n",
        "            \n",
        "    split_size =  int(np.ceil(len(input_values)/maps))\n",
        "    for i in range(0, len(input_values), split_size):\n",
        "        yield RECORDREADER(input_values[i:i+split_size])\n",
        "        \n",
        "def MAP(value:int, _):\n",
        "    yield (value, None)\n",
        "    \n",
        "def PARTITIONER(key):\n",
        "    global reducers\n",
        "    global max_value\n",
        "    global min_value\n",
        "    bucket_size = (max_value-min_value)/reducers\n",
        "    bucket_id = 0\n",
        "    while((key>(bucket_id+1)*bucket_size) and ((bucket_id+1)*bucket_size<max_value)):\n",
        "        bucket_id += 1\n",
        "    return bucket_id\n",
        "\n",
        "def REDUCE(value:int, _):\n",
        "    yield (None,value)\n",
        "    \n",
        "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None, PARTITIONER=PARTITIONER)\n",
        "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
        "partitioned_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQhoJaVZI93G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy65YJTH99iT"
      },
      "source": [
        "# Упражнения\n",
        "Упражнения взяты из Rajaraman A., Ullman J. D. Mining of massive datasets. – Cambridge University Press, 2011.\n",
        "\n",
        "\n",
        "Для выполнения заданий переопределите функции RECORDREADER, MAP, REDUCE. Для модели распределённой системы может потребоваться переопределение функций PARTITION и COMBINER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfvAeZm3S8S8"
      },
      "source": [
        "### Максимальное значение ряда\n",
        "\n",
        "Разработайте MapReduce алгоритм, который находит максимальное число входного списка чисел."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten(nested_iterable):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return t.items()\n",
        "\n",
        "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
        "    return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3GRA1JR-Tkbg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8 5 2 3 5 4 4 0 3 6] \n",
            " [4 6 7 3 5 9 3 6 9 0]\n",
            "[(0, np.int32(8)), (1, np.int32(9))]\n"
          ]
        }
      ],
      "source": [
        "arr1 = np.random.randint(size=(10),low=0,high=10)\n",
        "arr2 = np.random.randint(size=(10),low=0,high=10)\n",
        "\n",
        "def RECORDREADER():\n",
        "    for i in range(2):\n",
        "        for j in range(arr1.shape[0]):\n",
        "            yield ((i,j),(arr1,arr2)[i][j])\n",
        "\n",
        "def MAP(idx, value):\n",
        "    yield(idx[0], value)\n",
        "        \n",
        " \n",
        "def REDUCE(idx, iter):\n",
        "    max = 0\n",
        "    for i in iter:\n",
        "        if (max<i): max=i\n",
        "    yield (idx, max)\n",
        "\n",
        "print(arr1,'\\n',arr2)\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k86bXnqZTk-U"
      },
      "source": [
        "### Арифметическое среднее\n",
        "\n",
        "Разработайте MapReduce алгоритм, который находит арифметическое среднее.\n",
        "\n",
        "$$\\overline{X} = \\frac{1}{n}\\sum_{i=0}^{n} x_i$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MPoY5pkfUNZf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9 0 4 3 5 7 6 7 5 7] \n",
            " [9 5 7 3 8 8 7 6 6 9]\n",
            "[(0, np.float64(5.3)), (1, np.float64(6.8))]\n"
          ]
        }
      ],
      "source": [
        "arr1 = np.random.randint(size=(10),low=0,high=10)\n",
        "arr2 = np.random.randint(size=(10),low=0,high=10)\n",
        "\n",
        "def RECORDREADER():\n",
        "    for i in range(2):\n",
        "        for j in range(arr1.shape[0]):\n",
        "            yield ((i,j),(arr1,arr2)[i][j])\n",
        "\n",
        "def MAP(idx, value):\n",
        "    yield(idx[0], value)\n",
        "        \n",
        " \n",
        "def REDUCE(idx, iter):\n",
        "    sum = 0\n",
        "    for i in iter:\n",
        "        sum+=i\n",
        "    sum/=len(iter)\n",
        "    yield (idx, sum)\n",
        "\n",
        "print(arr1,'\\n',arr2)\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xanzszhsIlLe"
      },
      "source": [
        "### GroupByKey на основе сортировки\n",
        "\n",
        "Реализуйте groupByKey на основе сортировки, проверьте его работу на примерах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hQPn3USsIkEC"
      },
      "outputs": [],
      "source": [
        "def groupbykey(iterable):\n",
        "    # Сортируем входные данные по ключу\n",
        "    sorted_iterable = sorted(iterable, key=lambda x: x[0])\n",
        "\n",
        "    output = dict()\n",
        "\n",
        "    for (key, val) in sorted_iterable:\n",
        "        # Добавляем значение к соответствующему ключу\n",
        "        if key not in output:\n",
        "            output[key] = list()\n",
        "        output[key].append(val)\n",
        "\n",
        "    return output\n",
        "\n",
        "def flatten(nested_iterable):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
        "    return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(55, User(id=0, age=55, social_contacts=20, gender='female')), (25, User(id=1, age=25, social_contacts=240, gender='female')), (25, User(id=2, age=25, social_contacts=500, gender='female')), (33, User(id=3, age=33, social_contacts=800, gender='female'))]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{25: [User(id=1, age=25, social_contacts=240, gender='female'),\n",
              "  User(id=2, age=25, social_contacts=500, gender='female')],\n",
              " 33: [User(id=3, age=33, social_contacts=800, gender='female')],\n",
              " 55: [User(id=0, age=55, social_contacts=20, gender='female')]}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def MAP(_, row:NamedTuple):\n",
        "    if (row.gender == 'female'):\n",
        "        yield (row.age, row)\n",
        "\n",
        "def REDUCE(age:str, rows:Iterator[NamedTuple]):\n",
        "    sum = 0\n",
        "    count = 0\n",
        "    for row in rows:\n",
        "        sum += row.social_contacts\n",
        "        count += 1\n",
        "    if (count > 0):\n",
        "        yield (age, sum/count)\n",
        "    else:\n",
        "        yield (age, 0)\n",
        "\n",
        "def RECORDREADER():\n",
        "    return [(u.id, u) for u in input_collection]\n",
        "\n",
        "class User(NamedTuple):\n",
        "    id: int\n",
        "    age: str\n",
        "    social_contacts: int\n",
        "    gender: str\n",
        "\n",
        "input_collection = [\n",
        "    User(id=0, age=55, gender='female', social_contacts=20),\n",
        "    User(id=1, age=25, gender='female', social_contacts=240),\n",
        "    User(id=2, age=25, gender='female', social_contacts=500),\n",
        "    User(id=3, age=33, gender='female', social_contacts=800)\n",
        "]\n",
        "\n",
        "def RECORDREADER():\n",
        "    return [(u.id, u) for u in input_collection]\n",
        "\n",
        "map_output = flatten(map(lambda x: MAP(*x), RECORDREADER()))\n",
        "map_output = list(map_output) # materialize\n",
        "print(map_output)\n",
        "groupbykey(map_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SgEjCZyGnu6"
      },
      "source": [
        "### Drop duplicates (set construction, unique elements, distinct)\n",
        "\n",
        "Реализуйте распределённую операцию исключения дубликатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten(nested_iterable):\n",
        "  for iterable in nested_iterable:\n",
        "    for element in iterable:\n",
        "      yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "  t = {}\n",
        "  for (k2, v2) in iterable:\n",
        "    t[k2] = t.get(k2, []) + [v2]\n",
        "  return t.items()\n",
        "\n",
        "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
        "  global reducers\n",
        "  partitions = [dict() for _ in range(reducers)]\n",
        "  for map_partition in map_partitions:\n",
        "    for (k2, v2) in map_partition:\n",
        "      p = partitions[PARTITIONER(k2)]\n",
        "      p[k2] = p.get(k2, []) + [v2]\n",
        "  return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in enumerate(partitions)]\n",
        "\n",
        "def PARTITIONER(obj):\n",
        "  global reducers\n",
        "  return hash(obj) % reducers\n",
        "\n",
        "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
        "  map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
        "  if COMBINER != None:\n",
        "    map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
        "  reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER) # shuffle\n",
        "  reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
        "  return reduce_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "okjbyApjGhMt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('0:1', 'what is it'), ('0:2', 'what is it')]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0, ['it']), (1, ['is', 'what']), (2, [])]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "d1 = \"\"\"\n",
        "it is what it is\n",
        "it is what it is\n",
        "it is what it is\"\"\"\n",
        "d2 = \"\"\"\n",
        "what is it\n",
        "what is it\"\"\"\n",
        "d3 = \"\"\"\n",
        "it is a banana\"\"\"\n",
        "documents = [d2, d1, d2]\n",
        "\n",
        "\n",
        "maps = 2\n",
        "reducers = 3\n",
        "\n",
        "def INPUTFORMAT():\n",
        "  global maps\n",
        "\n",
        "  def RECORDREADER(split):\n",
        "    for (docid, document) in enumerate(split):\n",
        "      for (lineid, line) in enumerate(document.split('\\n')):\n",
        "        if line.strip():\n",
        "            yield (\"{}:{}\".format(docid,lineid), line)\n",
        "\n",
        "  split_size =  int(np.ceil(len(documents)/maps))\n",
        "  for i in range(0, len(documents), split_size):\n",
        "    yield RECORDREADER(documents[i:i+split_size])\n",
        "\n",
        "def MAP(docId:str, line:str):\n",
        "  for word in line.split():\n",
        "    if word.strip():\n",
        "        yield (word, 0)\n",
        "\n",
        "def REDUCE(key:str, values):\n",
        "  yield key\n",
        "\n",
        "print(list(list(INPUTFORMAT())[1]))\n",
        "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE)\n",
        "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
        "partitioned_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7sRGoTXuJze"
      },
      "source": [
        "# Операторы реляционной алгебры\n",
        "### Selection (Выборка)\n",
        "\n",
        "**The Map Function**: Для  каждого кортежа $t \\in R$ вычисляется истинность предиката $C$. В случае истины создаётся пара ключ-значение $(t, t)$. В паре ключ и значение одинаковы, равны $t$.\n",
        "\n",
        "**The Reduce Function:** Роль функции Reduce выполняет функция идентичности, которая возвращает то же значение, что получила на вход.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten(nested_iterable):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return t.items()\n",
        "\n",
        "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
        "    return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4nKIKe59uIfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 9, 6, 2, 9, 6, 8, 6, 5, 0] \n",
            " [8, 8, 9, 3, 5, 7, 9, 4, 8, 6]\n",
            "[{(1, 9, 6, 2, 9, 6, 8, 6, 5, 0): (1, 9, 6, 2, 9, 6, 8, 6, 5, 0), (8, 8, 9, 3, 5, 7, 9, 4, 8, 6): (8, 8, 9, 3, 5, 7, 9, 4, 8, 6)}]\n"
          ]
        }
      ],
      "source": [
        "arr1 = np.random.randint(size=(10),low=0,high=10).tolist()\n",
        "arr2 = np.random.randint(size=(10),low=0,high=10).tolist()\n",
        "\n",
        "def pred(t):\n",
        "    sr = 0\n",
        "    for i in t:\n",
        "        sr+=i\n",
        "    sr/=len(t)\n",
        "    if (sr > 4.5):return True\n",
        "    else: return False\n",
        "\n",
        "def mapp(tuples):\n",
        "    res = dict()\n",
        "    for i in range(len(tuples)):\n",
        "        if pred(tuples[i]):\n",
        "            res[tuples[i]] = tuples[i]\n",
        "    return res\n",
        "        \n",
        " \n",
        "def reduce(elem):\n",
        "    return (elem)\n",
        "\n",
        "def record_reader():\n",
        "    return (tuple(arr1), tuple(arr2))\n",
        "\n",
        "print(arr1,'\\n',arr2)\n",
        "\n",
        "output = reduce(list(map(mapp, [record_reader()])))\n",
        "output = list(output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w27Ca-_Ku85V"
      },
      "source": [
        "### Projection (Проекция)\n",
        "\n",
        "Проекция на множество атрибутов $S$.\n",
        "\n",
        "**The Map Function:** Для каждого кортежа $t \\in R$ создайте кортеж $t′$, исключая  из $t$ те значения, атрибуты которых не принадлежат  $S$. Верните пару $(t′, t′)$.\n",
        "\n",
        "**The Reduce Function:** Для каждого ключа $t′$, созданного любой Map задачей, вы получаете одну или несколько пар $(t′, t′)$. Reduce функция преобразует $(t′, [t′, t′, . . . , t′])$ в $(t′, t′)$, так, что для ключа $t′$ возвращается одна пара  $(t′, t′)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BEvuY4GqvhS6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 4, 3, 8, 0, 8, 3, 1, 8, 8] \n",
            " [7, 2, 8, 4, 8, 5, 2, 1, 6, 0]\n",
            "[((0, 4, 8, 0, 8, 8, 8), (0, 4, 8, 0, 8, 8, 8)), ((7, 8, 4, 8, 5, 6, 0), (7, 8, 4, 8, 5, 6, 0))]\n"
          ]
        }
      ],
      "source": [
        "arr1 = np.random.randint(size=(10),low=0,high=10).tolist()\n",
        "arr2 = np.random.randint(size=(10),low=0,high=10).tolist()\n",
        "S = set([1,2,3])\n",
        "\n",
        "\n",
        "def exclude_vals(t):\n",
        "    return tuple([i  for i in t  if i not in S])\n",
        "\n",
        "\n",
        "def mapp(t):\n",
        "    tex = exclude_vals(t)\n",
        "    return (tex,tex)\n",
        "        \n",
        " \n",
        "def reduce(key, value):\n",
        "    return (key, key)\n",
        "\n",
        "def record_reader():\n",
        "    return (tuple(arr1), tuple(arr2))\n",
        "\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return list(t.items())\n",
        "\n",
        "print(arr1,'\\n',arr2)\n",
        "\n",
        "output = map(lambda x: reduce(*x),  groupbykey(map(mapp, record_reader())))\n",
        "output = list(output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gau6lKXvn2R"
      },
      "source": [
        "### Union (Объединение)\n",
        "\n",
        "**The Map Function:** Превратите каждый входной кортеж $t$ в пару ключ-значение $(t, t)$.\n",
        "\n",
        "**The Reduce Function:** С каждым ключом $t$ будет ассоциировано одно или два значений. В обоих случаях создайте $(t, t)$ в качестве выходного значения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Sns7a5agv3nw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[((2, 2, 4), (2, 2, 4)), ((3, 3, 2), (3, 3, 2)), ((1, 3, 0), (1, 3, 0)), ((2, 0, 4), (2, 0, 4)), ((0, 0, 4), (0, 0, 4)), ((3, 4, 2), (3, 4, 2)), ((4, 3, 4), (4, 3, 4)), ((4, 0, 0), (4, 0, 0))]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "def mapp(t):\n",
        "    return (t,t)\n",
        "        \n",
        " \n",
        "def reduce(key, value):\n",
        "    return (key, key)\n",
        "\n",
        "def record_reader():\n",
        "    return [(random.randint(0, 4), random.randint(0, 4), random.randint(0, 4)) for _ in range(10)]\n",
        "\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return list(t.items())\n",
        "\n",
        "\n",
        "\n",
        "output = map(lambda x: reduce(*x),  groupbykey(map(mapp, record_reader())))\n",
        "output = list(output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ8TuEbjv4J8"
      },
      "source": [
        "### Intersection (Пересечение)\n",
        "\n",
        "**The Map Function:** Превратите каждый кортеж $t$ в пары ключ-значение $(t, t)$.\n",
        "\n",
        "**The Reduce Function:** Если для ключа $t$ есть список из двух элементов $[t, t]$ $-$ создайте пару $(t, t)$. Иначе, ничего не создавайте."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XKlBZh4IwERR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
          ]
        }
      ],
      "source": [
        "def mapp(t):\n",
        "    return (t,t)\n",
        "        \n",
        " \n",
        "def reduce(key, value):\n",
        "    if len(value)==2:\n",
        "        return (key, key)\n",
        "\n",
        "def record_reader():\n",
        "    return [(random.randint(0, 4), random.randint(0, 4), random.randint(0, 4)) for _ in range(20)]\n",
        "\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return list(t.items())\n",
        "\n",
        "\n",
        "\n",
        "output = map(lambda x: reduce(*x), groupbykey(map(mapp, record_reader())))\n",
        "output = list(output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVOpqoY3wE5k"
      },
      "source": [
        "### Difference (Разница)\n",
        "\n",
        "**The Map Function:** Для кортежа $t \\in R$, создайте пару $(t, R)$, и для кортежа $t \\in S$, создайте пару $(t, S)$. Задумка заключается в том, чтобы значение пары было именем отношения $R$ or $S$, которому принадлежит кортеж (а лучше, единичный бит, по которому можно два отношения различить $R$ or $S$), а не весь набор атрибутов отношения.\n",
        "\n",
        "**The Reduce Function:** Для каждого ключа $t$, если соответствующее значение является списком $[R]$, создайте пару $(t, t)$. В иных случаях не предпринимайте действий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QE_AC09lwZIZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[((3, 0, 1), (3, 0, 1)), None, ((3, 1, 4), (3, 1, 4)), None, None]\n"
          ]
        }
      ],
      "source": [
        "# True -- R; False -- S\n",
        "\n",
        "def mapp(t):\n",
        "    return t\n",
        "        \n",
        " \n",
        "def reduce(key, value):\n",
        "    if value[0]:\n",
        "        return (key, key)\n",
        "\n",
        "def record_reader():\n",
        "    return [((random.randint(0, 4), random.randint(0, 4), random.randint(0, 4)), bool(random.randint(0,1))) for _ in range(5)]\n",
        "\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return list(t.items())\n",
        "\n",
        "\n",
        "output = map(lambda x: reduce(*x), groupbykey(map(mapp, record_reader())))\n",
        "output = list(output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8I58V2VwhSm"
      },
      "source": [
        "### Natural Join\n",
        "\n",
        "**The Map Function:** Для каждого кортежа $(a, b)$ отношения $R$, создайте пару $(b,(R, a))$. Для каждого кортежа $(b, c)$ отношения $S$, создайте пару $(b,(S, c))$.\n",
        "\n",
        "**The Reduce Function:** Каждый ключ $b$ будет асоциирован со списком пар, которые принимают форму либо $(R, a)$, либо $(S, c)$. Создайте все пары, одни, состоящие из  первого компонента $R$, а другие, из первого компонента $S$, то есть $(R, a)$ и $(S, c)$. На выходе вы получаете последовательность пар ключ-значение из списков ключей и значений. Ключ не нужен. Каждое значение, это тройка $(a, b, c)$ такая, что $(R, a)$ и $(S, c)$ это принадлежат входному списку значений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yHiuuTctw86I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP: [(0, (True, 0)), (1, (False, 4)), (4, (True, 3)), (3, (False, 1)), (0, (True, 2))]\n",
            "Group: [(0, [(True, 0), (True, 2)]), (1, [(False, 4)]), (4, [(True, 3)]), (3, [(False, 1)])]\n",
            "Reduce: [None, None, None, None]\n"
          ]
        }
      ],
      "source": [
        "# True -- R; False -- S\n",
        "\n",
        "\n",
        "def mapp(key, val):\n",
        "    if val: key = (key[1], key[0])\n",
        "    return (key[0],(val,key[1]))\n",
        "        \n",
        " \n",
        "def reduce(key, values):\n",
        "    if (len(values) == 2) and (values[0][0]!=values[1][0]):\n",
        "        res = list()\n",
        "        a,c = 0, 0\n",
        "\n",
        "        for val in values:\n",
        "            if val[0]:\n",
        "                a = val[1]\n",
        "            else: \n",
        "                c = val[1]\n",
        "                \n",
        "\n",
        "        res.append(a)\n",
        "        res.append(key)\n",
        "        res.append(c)\n",
        "        return (res)\n",
        "\n",
        "def record_reader():\n",
        "    return [((random.randint(0, 4), random.randint(0, 4)), bool(random.randint(0,1))) for _ in range(5)]\n",
        "\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return list(t.items())\n",
        "\n",
        "\n",
        "# Генерация записей\n",
        "records = record_reader()\n",
        "\n",
        "# Применение MAP\n",
        "map_out = list(map(lambda x: mapp(*x), records))\n",
        "print(\"MAP:\", map_out)\n",
        "\n",
        "# Shuffle (группировка по ключу)\n",
        "shuffle_out = groupbykey(map_out)\n",
        "print(\"Group:\", shuffle_out)\n",
        "\n",
        "# Применение REDUCE\n",
        "reduce_out = [reduce(k, v) for k, v in shuffle_out]\n",
        "print(\"Reduce:\", reduce_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYdlr0YUxE27"
      },
      "source": [
        "### Grouping and Aggregation (Группировка и аггрегация)\n",
        "\n",
        "**The Map Function:** Для каждого кортежа $(a, b, c$) создайте пару $(a, b)$.\n",
        "\n",
        "**The Reduce Function:** Ключ представляет ту или иную группу. Примение аггрегирующую операцию $\\theta$ к списку значений $[b1, b2, . . . , bn]$ ассоциированных с ключом $a$. Возвращайте в выходной поток $(a, x)$, где $x$ результат применения  $\\theta$ к списку. Например, если $\\theta$ это $SUM$, тогда $x = b1 + b2 + · · · + bn$, а если $\\theta$ is $MAX$, тогда $x$ это максимальное из значений $b1, b2, . . . , bn$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MLPckfEGxico"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(3, 6), (1, 8), (4, 8), (2, 11)]\n"
          ]
        }
      ],
      "source": [
        "def mapp(t):\n",
        "    return (t[0], t[1])\n",
        "\n",
        "def agg(t):\n",
        "    return sum(t)\n",
        " \n",
        "def reduce(key, value):\n",
        "    return (key, agg(value))\n",
        "\n",
        "def record_reader():\n",
        "    return [(random.randint(0, 4), random.randint(0, 4), random.randint(0, 4)) for _ in range(20)]\n",
        "\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return list(t.items())\n",
        "\n",
        "\n",
        "output = map(lambda x: reduce(*x), groupbykey(map(mapp, record_reader())))\n",
        "output = list(output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03IffTEOJgOb"
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIrRgvG4RIS4"
      },
      "source": [
        "### Matrix-Vector multiplication\n",
        "\n",
        "Случай, когда вектор не помещается в памяти Map задачи\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, np.float64(1.2814756507186698)), (1, np.float64(1.2814756507186698)), (2, np.float64(1.2814756507186698)), (3, np.float64(1.2814756507186698)), (4, np.float64(1.2814756507186698))]\n"
          ]
        }
      ],
      "source": [
        "from typing import Iterator\n",
        "import numpy as np\n",
        "\n",
        "mat = np.ones((5,4))\n",
        "vec = np.random.rand(4)\n",
        "\n",
        "def MAP(idx, value:int):\n",
        "    if idx[0] == 'mat':\n",
        "        i, j = idx[1:]\n",
        "        yield (i, value*vec[j])\n",
        "\n",
        "def REDUCE(idx, products:Iterator[NamedTuple]):\n",
        "    sum = 0\n",
        "    for p in products:\n",
        "        sum += p\n",
        "    yield (idx, sum)\n",
        "\n",
        "def RECORDREADER():\n",
        "    for i in range(mat.shape[0]):\n",
        "        for j in range(mat.shape[1]):\n",
        "            yield (('mat',i, j), mat[i,j])\n",
        "\n",
        "    for i in range(vec.shape[0]):\n",
        "       yield (('vac',i), vec[i])\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIo2t7nNxvA9"
      },
      "source": [
        "## Matrix multiplication (Перемножение матриц)\n",
        "\n",
        "Если у нас есть матрица $M$ с элементами $m_{ij}$ в строке $i$ и столбце $j$, и матрица $N$ с элементами $n_{jk}$ в строке $j$ и столбце $k$, тогда их произведение $P = MN$ есть матрица $P$ с элементами $p_{ik}$ в строке $i$ и столбце $k$, где\n",
        "\n",
        "$$p_{ik} =\\sum_{j} m_{ij}n_{jk}$$\n",
        "\n",
        "Необходимым требованием является одинаковое количество столбцов в $M$ и строк в $N$, чтобы операция суммирования по  $j$ была осмысленной. Мы можем размышлять о матрице, как об отношении с тремя атрибутами: номер строки, номер столбца, само значение. Таким образом матрица $M$ предстваляется как отношение $ M(I, J, V )$, с кортежами $(i, j, m_{ij})$, и, аналогично, матрица $N$ представляется как отношение $N(J, K, W)$, с кортежами $(j, k, n_{jk})$. Так как большие матрицы как правило разреженные (большинство значений равно 0), и так как мы можем нулевыми значениями пренебречь (не хранить), такое реляционное представление достаточно эффективно для больших матриц. Однако, возможно, что координаты $i$, $j$, и $k$ неявно закодированы в смещение позиции элемента относительно начала файла, вместо явного хранения. Тогда, функция Map (или Reader) должна быть разработана таким образом, чтобы реконструировать компоненты $I$, $J$, и $K$ кортежей из смещения.\n",
        "\n",
        "Произведение $MN$ это фактически join, за которым следуют группировка по ключу и аггрегация. Таким образом join отношений $M(I, J, V )$ и $N(J, K, W)$, имеющих общим только атрибут $J$, создаст кортежи $(i, j, k, v, w)$ из каждого кортежа $(i, j, v) \\in M$ и кортежа $(j, k, w) \\in N$. Такой 5 компонентный кортеж представляет пару элементов матрицы $(m_{ij} , n_{jk})$. Что нам хотелось бы получить на самом деле, это произведение этих элементов, то есть, 4 компонентный кортеж$(i, j, k, v \\times w)$, так как он представляет произведение $m_{ij}n_{jk}$. Мы представляем отношение как результат одной MapReduce операции, в которой мы можем произвести группировку и аггрегацию, с $I$ и $K$  атрибутами, по которым идёт группировка, и суммой  $V \\times W$. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1MBkGaLAYVCt"
      },
      "outputs": [],
      "source": [
        "# MapReduce model\n",
        "def flatten(nested_iterable):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return t.items()\n",
        "\n",
        "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
        "    return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMspsOT0ZB35"
      },
      "source": [
        "Реализуйте перемножение матриц с использованием модельного кода MapReduce для одной машины в случае, когда одна матрица хранится в памяти, а другая генерируется RECORDREADER-ом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "psP1XekbsEjS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "I = 2\n",
        "J = 3\n",
        "K = 4*10\n",
        "small_mat = np.random.rand(I,J) # it is legal to access this from RECORDREADER, MAP, REDUCE\n",
        "big_mat = np.random.rand(J,K)\n",
        "\n",
        "def RECORDREADER():\n",
        "    for j in range(big_mat.shape[0]):\n",
        "        for k in range(big_mat.shape[1]):\n",
        "            yield ((j,k), big_mat[j,k])\n",
        "            \n",
        "def MAP(k1, v1):\n",
        "    (j, k) = k1\n",
        "    w = v1\n",
        "    for i in range(I):\n",
        "        yield ((i, k), small_mat[i, j] * w)\n",
        "    \n",
        "def REDUCE(key, values):\n",
        "    (i, k) = key\n",
        "    yield (key, sum(values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnt306LHhHrm"
      },
      "source": [
        "Проверьте своё решение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Ewy_ZNYqW5a2",
        "outputId": "9ce264f2-9412-44e2-9b0a-cc780573ab3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# CHECK THE SOLUTION\n",
        "reference_solution = np.matmul(small_mat, big_mat) \n",
        "solution = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "\n",
        "def asmatrix(reduce_output):\n",
        "    reduce_output = list(reduce_output)\n",
        "    I = max(i for ((i,k), vw) in reduce_output)+1\n",
        "    K = max(k for ((i,k), vw) in reduce_output)+1\n",
        "    mat = np.empty(shape=(I,K))\n",
        "    for ((i,k), vw) in reduce_output:\n",
        "        mat[i,k] = vw\n",
        "    return mat\n",
        "\n",
        "np.allclose(reference_solution, asmatrix(solution)) # should return true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "TK7v4CEcfxqf",
        "outputId": "2c865d0a-4065-4e6b-c83f-5508ed5eb4fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reduce_output = list(MapReduce(RECORDREADER, MAP, REDUCE))\n",
        "max(i for ((i,k), vw) in reduce_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4yyg3kOZqJJ"
      },
      "source": [
        "Реализуйте перемножение матриц  с использованием модельного кода MapReduce для одной машины в случае, когда обе матрицы генерируются в RECORDREADER. Например, сначала одна, а потом другая."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "3B7rIAJCaHZq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "I = 2\n",
        "J = 3\n",
        "K = 4*10\n",
        "small_mat = np.random.rand(I,J)\n",
        "big_mat = np.random.rand(J,K)\n",
        "\n",
        "def RECORDREADER():\n",
        "    for j in range(big_mat.shape[0]):\n",
        "        for k in range(big_mat.shape[1]):\n",
        "            yield (('big',j,k), big_mat[j,k])\n",
        "    \n",
        "    for j in range(small_mat.shape[0]):\n",
        "        for i in range(small_mat.shape[1]):\n",
        "            yield (('small',j,i), small_mat[j,i])\n",
        "\n",
        "           \n",
        "def MAP(k1, v1):\n",
        "    if k1[0] == 'small':\n",
        "        j, i = k1[1:]\n",
        "        w = v1\n",
        "        for k in range(big_mat.shape[1]):\n",
        "            yield ((j, k), big_mat[i, k] * w)\n",
        "    \n",
        "    \n",
        "def REDUCE(key, values):\n",
        "    (i, k) = key\n",
        "    yield (key, sum(values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# CHECK THE SOLUTION\n",
        "reference_solution = np.matmul(small_mat, big_mat)\n",
        "solution = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "\n",
        "# Verify if the solution matches the reference\n",
        "print(np.allclose(reference_solution, asmatrix(solution)))  # should return true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXyzQi1DaIwo"
      },
      "source": [
        "Реализуйте перемножение матриц с использованием модельного кода MapReduce Distributed, когда каждая матрица генерируется в своём RECORDREADER. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "TDM_s78Rb5eR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "I = 2\n",
        "J = 3\n",
        "K = 4*10\n",
        "small_mat = np.random.rand(I,J)\n",
        "big_mat = np.random.rand(J,K)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten(nested_iterable):\n",
        "    \"\"\"A function for aligning nested iterable objects.\"\"\"\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def group_by_key(iterable):\n",
        "    grouped = {}\n",
        "    for (key, value) in iterable:\n",
        "        grouped[key] = grouped.get(key, []) + [value]\n",
        "    return grouped.items()\n",
        "\n",
        "def group_by_key_distributed(map_partitions, partitioner):\n",
        "    \"\"\"Distributed grouping by key.\"\"\"\n",
        "    global num_reducers\n",
        "    partitions = [dict() for _ in range(num_reducers)]\n",
        "    for map_partition in map_partitions:\n",
        "        for (key, value) in map_partition:\n",
        "            partition_id = partitions[partitioner(key)]\n",
        "            partition_id[key] = partition_id.get(key, []) + [value]\n",
        "    return [(i, sorted(partition.items(), key=lambda x: x[0])) for i, partition in enumerate(partitions)]\n",
        "\n",
        "def partitioner(obj):\n",
        "    \"\"\"Function for determining the batch number.\"\"\"\n",
        "    global num_reducers\n",
        "    return hash(obj) % num_reducers\n",
        "\n",
        "def MapReduceDistributed(input_format, map_func, reduce_func, partitioner=partitioner, combiner=None):\n",
        "\n",
        "    map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: map_func(*k1v1), record_reader)), input_format())\n",
        "    if combiner is not None:\n",
        "        map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: combiner(*k2v2), group_by_key(map_partition))), map_partitions)\n",
        "    reduce_partitions = group_by_key_distributed(map_partitions, partitioner)\n",
        "    reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: reduce_func(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
        "\n",
        "    print(\"{} key-value pairs were sent over a network.\".format(sum(len(vs) for (k, vs) in flatten([partition for (partition_id, partition) in reduce_partitions]))))\n",
        "    return reduce_outputs\n",
        "\n",
        "def as_matrix(reduce_output):\n",
        "    \"\"\"Converting the reduction output to a matrix.\"\"\"\n",
        "    reduce_output = list(reduce_output)\n",
        "    rows = max(i for ((i, k), vw) in reduce_output) + 1\n",
        "    cols = max(k for ((i, k), vw) in reduce_output) + 1\n",
        "    result_matrix = np.empty(shape=(rows, cols))\n",
        "\n",
        "    for ((i, k), vw) in reduce_output:\n",
        "        result_matrix[i, k] = vw\n",
        "\n",
        "    return result_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126 key-value pairs were sent over a network.\n",
            "[(0, [((0, 0), np.float64(0.3830385512615493)), ((0, 1), np.float64(0.22716642291325137)), ((0, 2), np.float64(0.2505250263576772)), ((1, 0), np.float64(0.8105419999645681)), ((1, 1), np.float64(0.4807033812823086)), ((1, 2), np.float64(0.5301321635546604)), ((2, 0), np.float64(0.25240993675415774)), ((2, 1), np.float64(0.14969527806366764)), ((2, 2), np.float64(0.16508783737304916))]), (1, [((0, 0), np.float64(0.16625391015635052)), ((0, 1), np.float64(0.03017572575045533)), ((0, 2), np.float64(0.1300893560343794)), ((1, 0), np.float64(0.3028584109580376)), ((1, 1), np.float64(0.05496996937812684)), ((1, 2), np.float64(0.2369788212143389)), ((2, 0), np.float64(0.7251429731975929)), ((2, 1), np.float64(0.13161624570815855)), ((2, 2), np.float64(0.567405496372482))])]\n",
            "Join Part: (0, [((0, 0), np.float64(0.3830385512615493)), ((0, 1), np.float64(0.22716642291325137)), ((0, 2), np.float64(0.2505250263576772)), ((1, 0), np.float64(0.8105419999645681)), ((1, 1), np.float64(0.4807033812823086)), ((1, 2), np.float64(0.5301321635546604)), ((2, 0), np.float64(0.25240993675415774)), ((2, 1), np.float64(0.14969527806366764)), ((2, 2), np.float64(0.16508783737304916))])\n",
            "Join Part: (1, [((0, 0), np.float64(0.16625391015635052)), ((0, 1), np.float64(0.03017572575045533)), ((0, 2), np.float64(0.1300893560343794)), ((1, 0), np.float64(0.3028584109580376)), ((1, 1), np.float64(0.05496996937812684)), ((1, 2), np.float64(0.2369788212143389)), ((2, 0), np.float64(0.7251429731975929)), ((2, 1), np.float64(0.13161624570815855)), ((2, 2), np.float64(0.567405496372482))])\n",
            "18 key-value pairs were sent over a network.\n",
            "[(0, [((0, 1), np.float64(0.2573421486637067)), ((0, 2), np.float64(0.3806143823920566)), ((1, 0), np.float64(1.1134004109226057)), ((1, 1), np.float64(0.5356733506604354)), ((2, 0), np.float64(0.9775529099517506))]), (1, [((0, 0), np.float64(0.5492924614178998)), ((1, 2), np.float64(0.7671109847689993)), ((2, 1), np.float64(0.2813115237718262)), ((2, 2), np.float64(0.7324933337455313))])]\n",
            "[((0, 1), np.float64(0.2573421486637067)), ((0, 2), np.float64(0.3806143823920566)), ((1, 0), np.float64(1.1134004109226057)), ((1, 1), np.float64(0.5356733506604354)), ((2, 0), np.float64(0.9775529099517506)), ((0, 0), np.float64(0.5492924614178998)), ((1, 2), np.float64(0.7671109847689993)), ((2, 1), np.float64(0.2813115237718262)), ((2, 2), np.float64(0.7324933337455313))]\n"
          ]
        }
      ],
      "source": [
        "def input_format():\n",
        "    def RECORDREADER_B(prefix):\n",
        "        big_mat_list = list()\n",
        "        for j in range(big_mat.shape[0]):\n",
        "            for i in range(big_mat.shape[1]):\n",
        "                big_mat_list.append(((prefix,j,i), big_mat[j,i]))\n",
        "        return big_mat_list\n",
        "\n",
        "    def RECORDREADER_S(prefix):\n",
        "        small_mat_list = list()\n",
        "        for j in range(small_mat.shape[0]):\n",
        "            for i in range(small_mat.shape[1]):\n",
        "                small_mat_list.append(((prefix,j,i), small_mat[j,i]))\n",
        "        return small_mat_list\n",
        "\n",
        "    yield RECORDREADER_S(\"small\")\n",
        "\n",
        "    yield RECORDREADER_B(\"big\")\n",
        "\n",
        "\n",
        "def map_join(key1, value1):\n",
        "\n",
        "    matrix_id, i, j = key1\n",
        "    value = value1\n",
        "\n",
        "    if matrix_id == 'big':\n",
        "        yield (j, (matrix_id, i, value))\n",
        "    elif matrix_id == 'small':\n",
        "        yield (i, (matrix_id, j, value))\n",
        "    else: pass\n",
        "\n",
        "def reduce_join(key, values):\n",
        "    big_matr_values = [v for v in values if v[0] == 'big']\n",
        "    small_mat_values = [v for v in values if v[0] == 'small']\n",
        "\n",
        "    for a in big_matr_values:\n",
        "        for b in small_mat_values:\n",
        "            yield ((a[1], b[1]), a[2] * b[2])\n",
        "\n",
        "def get_joined():\n",
        "    for j in joined:\n",
        "        print(\"Join Part:\", j)\n",
        "        yield j[1]\n",
        "\n",
        "def map_multiply(key1, value1):\n",
        "    yield (key1, value1)\n",
        "\n",
        "def reduce_multiply(key, values):\n",
        "    yield (key, sum(values))\n",
        "\n",
        "num_maps = 3\n",
        "num_reducers = 2\n",
        "\n",
        "partitioned_output = MapReduceDistributed(input_format, map_join, reduce_join)\n",
        "joined = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
        "print(joined)\n",
        "\n",
        "mul_output = MapReduceDistributed(get_joined, map_multiply, reduce_multiply)\n",
        "pre_result = [(partition_id, list(partition)) for (partition_id, partition) in mul_output]\n",
        "print(pre_result)\n",
        "\n",
        "\n",
        "solution_values = []\n",
        "for p in pre_result:\n",
        "    solution_values.extend(p[1])\n",
        "\n",
        "print(solution_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuSA2P9Db6UM"
      },
      "source": [
        "Обобщите предыдущее решение на случай, когда каждая матрица генерируется несколькими RECORDREADER-ами, и проверьте его работоспособность. Будет ли работать решение, если RECORDREADER-ы будут генерировать случайное подмножество элементов матрицы?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ehN0FqRDcwU5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126 key-value pairs were sent over a network.\n",
            "[(0, [((0, 0), np.float64(0.3830385512615493)), ((0, 1), np.float64(0.22716642291325137)), ((0, 2), np.float64(0.2505250263576772)), ((1, 0), np.float64(0.8105419999645681)), ((1, 1), np.float64(0.4807033812823086)), ((1, 2), np.float64(0.5301321635546604)), ((2, 0), np.float64(0.25240993675415774)), ((2, 1), np.float64(0.14969527806366764)), ((2, 2), np.float64(0.16508783737304916))]), (1, [((0, 0), np.float64(0.16625391015635052)), ((0, 1), np.float64(0.03017572575045533)), ((0, 2), np.float64(0.1300893560343794)), ((1, 0), np.float64(0.3028584109580376)), ((1, 1), np.float64(0.05496996937812684)), ((1, 2), np.float64(0.2369788212143389)), ((2, 0), np.float64(0.7251429731975929)), ((2, 1), np.float64(0.13161624570815855)), ((2, 2), np.float64(0.567405496372482))])]\n",
            "Join Part: (0, [((0, 0), np.float64(0.3830385512615493)), ((0, 1), np.float64(0.22716642291325137)), ((0, 2), np.float64(0.2505250263576772)), ((1, 0), np.float64(0.8105419999645681)), ((1, 1), np.float64(0.4807033812823086)), ((1, 2), np.float64(0.5301321635546604)), ((2, 0), np.float64(0.25240993675415774)), ((2, 1), np.float64(0.14969527806366764)), ((2, 2), np.float64(0.16508783737304916))])\n",
            "Join Part: (1, [((0, 0), np.float64(0.16625391015635052)), ((0, 1), np.float64(0.03017572575045533)), ((0, 2), np.float64(0.1300893560343794)), ((1, 0), np.float64(0.3028584109580376)), ((1, 1), np.float64(0.05496996937812684)), ((1, 2), np.float64(0.2369788212143389)), ((2, 0), np.float64(0.7251429731975929)), ((2, 1), np.float64(0.13161624570815855)), ((2, 2), np.float64(0.567405496372482))])\n",
            "18 key-value pairs were sent over a network.\n",
            "[(0, [((0, 1), np.float64(0.2573421486637067)), ((0, 2), np.float64(0.3806143823920566)), ((1, 0), np.float64(1.1134004109226057)), ((1, 1), np.float64(0.5356733506604354)), ((2, 0), np.float64(0.9775529099517506))]), (1, [((0, 0), np.float64(0.5492924614178998)), ((1, 2), np.float64(0.7671109847689993)), ((2, 1), np.float64(0.2813115237718262)), ((2, 2), np.float64(0.7324933337455313))])]\n",
            "[((0, 1), np.float64(0.2573421486637067)), ((0, 2), np.float64(0.3806143823920566)), ((1, 0), np.float64(1.1134004109226057)), ((1, 1), np.float64(0.5356733506604354)), ((2, 0), np.float64(0.9775529099517506)), ((0, 0), np.float64(0.5492924614178998)), ((1, 2), np.float64(0.7671109847689993)), ((2, 1), np.float64(0.2813115237718262)), ((2, 2), np.float64(0.7324933337455313))]\n"
          ]
        }
      ],
      "source": [
        "def input_format():\n",
        "    def RECORDREADER_B(prefix):\n",
        "        big_mat_list = list()\n",
        "        for j in range(big_mat.shape[0]):\n",
        "            for i in range(big_mat.shape[1]):\n",
        "                big_mat_list.append(((prefix,j,i), big_mat[j,i]))\n",
        "        return big_mat_list\n",
        "\n",
        "    def RECORDREADER_S(prefix):\n",
        "        small_mat_list = list()\n",
        "        for j in range(small_mat.shape[0]):\n",
        "            for i in range(small_mat.shape[1]):\n",
        "                small_mat_list.append(((prefix,j,i), small_mat[j,i]))\n",
        "        return small_mat_list\n",
        "\n",
        "    global num_maps\n",
        "    split_size = int(np.ceil(big_mat.shape[0]*big_mat.shape[1] / num_maps))\n",
        "\n",
        "    for i in range(0, big_mat.shape[0]*big_mat.shape[1], split_size):\n",
        "        yield RECORDREADER_B(\"big\")[i:i + split_size]\n",
        "\n",
        "    split_size = int(np.ceil(small_mat.shape[0]*small_mat.shape[1] / num_maps))\n",
        "\n",
        "    for i in range(0, small_mat.shape[0]*small_mat.shape[1], split_size):\n",
        "        yield RECORDREADER_S(\"small\")[i:i + split_size]\n",
        "\n",
        "\n",
        "def map_join(key1, value1):\n",
        "\n",
        "    matrix_id, i, j = key1\n",
        "    value = value1\n",
        "\n",
        "    if matrix_id == 'big':\n",
        "        yield (j, (matrix_id, i, value))\n",
        "    elif matrix_id == 'small':\n",
        "        yield (i, (matrix_id, j, value))\n",
        "    else: pass\n",
        "\n",
        "def reduce_join(key, values):\n",
        "    big_matr_values = [v for v in values if v[0] == 'big']\n",
        "    small_mat_values = [v for v in values if v[0] == 'small']\n",
        "\n",
        "    for a in big_matr_values:\n",
        "        for b in small_mat_values:\n",
        "            yield ((a[1], b[1]), a[2] * b[2])\n",
        "\n",
        "def get_joined():\n",
        "    for j in joined:\n",
        "        print(\"Join Part:\", j)\n",
        "        yield j[1]\n",
        "\n",
        "def map_multiply(key1, value1):\n",
        "    yield (key1, value1)\n",
        "\n",
        "def reduce_multiply(key, values):\n",
        "    yield (key, sum(values))\n",
        "\n",
        "num_maps = 3\n",
        "num_reducers = 2\n",
        "\n",
        "partitioned_output = MapReduceDistributed(input_format, map_join, reduce_join)\n",
        "joined = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
        "print(joined)\n",
        "\n",
        "mul_output = MapReduceDistributed(get_joined, map_multiply, reduce_multiply)\n",
        "pre_result = [(partition_id, list(partition)) for (partition_id, partition) in mul_output]\n",
        "print(pre_result)\n",
        "\n",
        "\n",
        "solution_values = []\n",
        "for p in pre_result:\n",
        "    solution_values.extend(p[1])\n",
        "\n",
        "print(solution_values)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
